{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "448c3017",
   "metadata": {},
   "source": [
    "Before using this notebook enshure to create a new conda environment and a new kernel like so:\n",
    "Execute this commands in a shell:\n",
    "\"\"\"\n",
    "conda create -n \"paper\"\n",
    "conda activate paper\n",
    "conda install ipykernel\n",
    "ipython kernel install --user --name=paperKernel\n",
    "conda deactivate\n",
    "\"\"\"\n",
    "Then start in this notebook with the new kernel \"paperKernel\" selected\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "58a071df",
   "metadata": {
    "collapsed": true,
    "editable": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "scrolled": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Channels:\n",
      " - pytorch\n",
      " - nvidia\n",
      " - defaults\n",
      " - conda-forge\n",
      " - dglteam/label/th22_cu121\n",
      " - pyg\n",
      "Platform: linux-64\n",
      "Collecting package metadata (repodata.json): done\n",
      "Solving environment: done\n",
      "\n",
      "# All requested packages already installed.\n",
      "\n",
      "\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Channels:\n",
      " - pyg\n",
      " - defaults\n",
      " - conda-forge\n",
      " - nvidia\n",
      " - dglteam/label/th22_cu121\n",
      " - pytorch\n",
      "Platform: linux-64\n",
      "Collecting package metadata (repodata.json): done\n",
      "Solving environment: done\n",
      "\n",
      "# All requested packages already installed.\n",
      "\n",
      "\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Channels:\n",
      " - conda-forge\n",
      " - defaults\n",
      " - nvidia\n",
      " - dglteam/label/th22_cu121\n",
      " - pytorch\n",
      " - pyg\n",
      "Platform: linux-64\n",
      "Collecting package metadata (repodata.json): done\n",
      "Solving environment: done\n",
      "\n",
      "## Package Plan ##\n",
      "\n",
      "  environment location: /home/schwollie/anaconda3/envs/paper\n",
      "\n",
      "  added / updated specs:\n",
      "    - lightning\n",
      "\n",
      "\n",
      "The following packages will be SUPERSEDED by a higher-priority channel:\n",
      "\n",
      "  certifi            pkgs/main/linux-64::certifi-2024.2.2-~ --> conda-forge/noarch::certifi-2024.2.2-pyhd8ed1ab_0 \n",
      "\n",
      "\n",
      "\n",
      "Downloading and Extracting Packages:\n",
      "\n",
      "Preparing transaction: done\n",
      "Verifying transaction: done\n",
      "Executing transaction: done\n",
      "\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Channels:\n",
      " - defaults\n",
      " - conda-forge\n",
      " - nvidia\n",
      " - dglteam/label/th22_cu121\n",
      " - pytorch\n",
      " - pyg\n",
      "Platform: linux-64\n",
      "Collecting package metadata (repodata.json): done\n",
      "Solving environment: done\n",
      "\n",
      "## Package Plan ##\n",
      "\n",
      "  environment location: /home/schwollie/anaconda3/envs/paper\n",
      "\n",
      "  added / updated specs:\n",
      "    - ogb\n",
      "    - pandas\n",
      "    - performer-pytorch\n",
      "    - scikit-learn\n",
      "    - wandb\n",
      "    - yacs\n",
      "\n",
      "\n",
      "The following packages will be SUPERSEDED by a higher-priority channel:\n",
      "\n",
      "  certifi            conda-forge/noarch::certifi-2024.2.2-~ --> pkgs/main/linux-64::certifi-2024.2.2-py312h06a4308_0 \n",
      "\n",
      "\n",
      "\n",
      "Downloading and Extracting Packages:\n",
      "\n",
      "Preparing transaction: done\n",
      "Verifying transaction: done\n",
      "Executing transaction: done\n",
      "\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Channels:\n",
      " - conda-forge\n",
      " - defaults\n",
      " - nvidia\n",
      " - dglteam/label/th22_cu121\n",
      " - pytorch\n",
      " - pyg\n",
      "Platform: linux-64\n",
      "Collecting package metadata (repodata.json): done\n",
      "Solving environment: done\n",
      "\n",
      "## Package Plan ##\n",
      "\n",
      "  environment location: /home/schwollie/anaconda3/envs/paper\n",
      "\n",
      "  added / updated specs:\n",
      "    - fsspec\n",
      "    - openbabel\n",
      "    - rdkit\n",
      "\n",
      "\n",
      "The following packages will be SUPERSEDED by a higher-priority channel:\n",
      "\n",
      "  certifi            pkgs/main/linux-64::certifi-2024.2.2-~ --> conda-forge/noarch::certifi-2024.2.2-pyhd8ed1ab_0 \n",
      "\n",
      "\n",
      "\n",
      "Downloading and Extracting Packages:\n",
      "\n",
      "Preparing transaction: done\n",
      "Verifying transaction: done\n",
      "Executing transaction: done\n",
      "\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%conda install pytorch torchvision torchaudio pytorch-cuda=12.1 -c pytorch -c nvidia\n",
    "%conda install pyg -c pyg \n",
    "%conda install lightning -c conda-forge\n",
    "%conda install yacs ogb pandas scikit-learn performer-pytorch wandb\n",
    "%conda install openbabel fsspec rdkit -c conda-forge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "809d6d9f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.2.2\n",
      "12.1\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "print(torch.__version__)\n",
    "print(torch.version.cuda)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0237c31f-03f0-4984-b868-94cd6c4ec0a7",
   "metadata": {},
   "source": [
    "Install additional packages and replace with cuda and torch version:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b0b704f0-6f2b-4aa5-8d89-bbd4a6a58a4b",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking in links: https://data.pyg.org/whl/torch-2.2.2+cu121.html\n",
      "Requirement already satisfied: pyg_lib in /home/schwollie/anaconda3/envs/paper/lib/python3.12/site-packages (0.4.0+pt22cu121)\n",
      "Requirement already satisfied: torch_scatter in /home/schwollie/anaconda3/envs/paper/lib/python3.12/site-packages (2.1.2+pt22cu121)\n",
      "Requirement already satisfied: torch_sparse in /home/schwollie/anaconda3/envs/paper/lib/python3.12/site-packages (0.6.18+pt22cu121)\n",
      "Requirement already satisfied: torch_cluster in /home/schwollie/anaconda3/envs/paper/lib/python3.12/site-packages (1.6.3+pt22cu121)\n",
      "Requirement already satisfied: torch_spline_conv in /home/schwollie/anaconda3/envs/paper/lib/python3.12/site-packages (1.2.2+pt22cu121)\n",
      "Requirement already satisfied: scipy in /home/schwollie/anaconda3/envs/paper/lib/python3.12/site-packages (from torch_sparse) (1.13.0)\n",
      "Requirement already satisfied: numpy<2.3,>=1.22.4 in /home/schwollie/anaconda3/envs/paper/lib/python3.12/site-packages (from scipy->torch_sparse) (1.26.4)\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Channels:\n",
      " - dglteam/label/th22_cu121\n",
      " - defaults\n",
      " - conda-forge\n",
      " - nvidia\n",
      " - pytorch\n",
      " - pyg\n",
      "Platform: linux-64\n",
      "Collecting package metadata (repodata.json): done\n",
      "Solving environment: done\n",
      "\n",
      "## Package Plan ##\n",
      "\n",
      "  environment location: /home/schwollie/anaconda3/envs/paper\n",
      "\n",
      "  added / updated specs:\n",
      "    - dgl\n",
      "\n",
      "\n",
      "The following packages will be SUPERSEDED by a higher-priority channel:\n",
      "\n",
      "  certifi            conda-forge/noarch::certifi-2024.2.2-~ --> pkgs/main/linux-64::certifi-2024.2.2-py312h06a4308_0 \n",
      "\n",
      "\n",
      "\n",
      "Downloading and Extracting Packages:\n",
      "\n",
      "Preparing transaction: done\n",
      "Verifying transaction: done\n",
      "Executing transaction: done\n",
      "\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install pyg_lib torch_scatter torch_sparse torch_cluster torch_spline_conv -f https://data.pyg.org/whl/torch-2.2.2+cu121.html\n",
    "%conda install -c dglteam/label/th22_cu121 dgl"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc5ce606-230f-455a-b30f-740b81a6f267",
   "metadata": {},
   "source": [
    "Setup run configurations:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c1e0700b-b67c-4f8e-ba14-10f0517e718c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Errno 2] No such file or directory: 'experiment1'\n",
      "/home/schwollie/Documents/Code/Uni/paper/experiment1\n",
      "conda activate paper\n",
      "\n",
      "# peptidesfunc:\n",
      "python main.py --cfg configs/GCN/peptides-func-GCN.yaml  wandb.use False\n",
      "python main.py --cfg configs/GCN/VN-peptides-func-GCN.yaml  wandb.use False\n",
      "\n",
      "python main.py --cfg configs/GatedGCN/peptides-func-GatedGCN.yaml  wandb.use False\n",
      "python main.py --cfg configs/GatedGCN/VN-peptides-func-GatedGCN.yaml  wandb.use False\n",
      "\n",
      "python main.py --cfg configs/GINE/peptides-func-GINE.yaml  wandb.use False\n",
      "python main.py --cfg configs/GINE/VN-peptides-func-GINE.yaml  wandb.use False\n",
      "\n",
      "python main.py --cfg configs/SAN/peptides-func-SAN.yaml  wandb.use False\n",
      "python main.py --cfg configs/SAN/peptides-func-SAN+RWSE.yaml  wandb.use False\n",
      "\n",
      "#peptidesstruct:\n",
      "python main.py --cfg configs/GCN/peptides-struct-GCN.yaml  wandb.use False\n",
      "python main.py --cfg configs/GCN/VN-peptides-struct-GCN.yaml  wandb.use False\n",
      "\n",
      "python main.py --cfg configs/GatedGCN/peptides-struct-GatedGCN.yaml  wandb.use False\n",
      "python main.py --cfg configs/GatedGCN/VN-peptides-struct-GatedGCN.yaml  wandb.use False\n",
      "\n",
      "python main.py --cfg configs/GINE/peptides-struct-GINE.yaml  wandb.use False\n",
      "python main.py --cfg configs/GINE/VN-peptides-struct-GINE.yaml  wandb.use False\n",
      "\n",
      "python main.py --cfg configs/SAN/peptides-struct-SAN.yaml  wandb.use False\n",
      "python main.py --cfg configs/SAN/peptides-struct-SAN+RWSE.yaml  wandb.use FalseNamespace(cfg_file='configs/GCN/peptides-func-GCN.yaml', repeat=1, mark_done=False, opts=['wandb.use', 'False'])\n",
      "[*] Run ID 0: seed=0, split_index=0\n",
      "    Starting now: 2024-05-20 12:52:43.904996\n",
      "[*] Loaded dataset 'peptides-functional' from 'OGB':\n",
      "/home/schwollie/anaconda3/envs/paper/lib/python3.12/site-packages/torch_geometric/data/in_memory_dataset.py:300: UserWarning: It is not recommended to directly access the internal storage format `data` of an 'InMemoryDataset'. If you are absolutely certain what you are doing, access the internal storage via `InMemoryDataset._data` instead to suppress this warning. Alternatively, you can access stacked individual attributes of every graph via `dataset.{attr_name}`.\n",
      "  warnings.warn(msg)\n",
      "  Data(edge_index=[2, 4773974], edge_attr=[4773974, 3], x=[2344859, 9], y=[15535, 10])\n",
      "  undirected: True\n",
      "  num graphs: 15535\n",
      "/home/schwollie/anaconda3/envs/paper/lib/python3.12/site-packages/torch_geometric/data/in_memory_dataset.py:300: UserWarning: It is not recommended to directly access the internal storage format `data` of an 'InMemoryDataset'. The data of the dataset is already cached, so any modifications to `data` will not be reflected when accessing its elements. Clearing the cache now by removing all elements in `dataset._data_list`. If you are absolutely certain what you are doing, access the internal storage via `InMemoryDataset._data` instead to suppress this warning. Alternatively, you can access stacked individual attributes of every graph via `dataset.{attr_name}`.\n",
      "  warnings.warn(msg)\n",
      "  avg num_nodes/graph: 150\n",
      "  num node features: 9\n",
      "  num edge features: 3\n",
      "  num classes: 10\n",
      "GraphGymModule(\n",
      "  (model): GNN(\n",
      "    (encoder): FeatureEncoder(\n",
      "      (node_encoder): AtomEncoder(\n",
      "        (atom_embedding_list): ModuleList(\n",
      "          (0): Embedding(119, 300)\n",
      "          (1): Embedding(5, 300)\n",
      "          (2-3): 2 x Embedding(12, 300)\n",
      "          (4): Embedding(10, 300)\n",
      "          (5-6): 2 x Embedding(6, 300)\n",
      "          (7-8): 2 x Embedding(2, 300)\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (mp): GNNStackStage(\n",
      "      (layer0): GeneralLayer(\n",
      "        (layer): GCNConv(\n",
      "          (model): GCNConv(300, 300)\n",
      "        )\n",
      "        (post_layer): Sequential(\n",
      "          (0): BatchNorm1d(300, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (1): ReLU()\n",
      "        )\n",
      "      )\n",
      "      (layer1): GeneralLayer(\n",
      "        (layer): GCNConv(\n",
      "          (model): GCNConv(300, 300)\n",
      "        )\n",
      "        (post_layer): Sequential(\n",
      "          (0): BatchNorm1d(300, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (1): ReLU()\n",
      "        )\n",
      "      )\n",
      "      (layer2): GeneralLayer(\n",
      "        (layer): GCNConv(\n",
      "          (model): GCNConv(300, 300)\n",
      "        )\n",
      "        (post_layer): Sequential(\n",
      "          (0): BatchNorm1d(300, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (1): ReLU()\n",
      "        )\n",
      "      )\n",
      "      (layer3): GeneralLayer(\n",
      "        (layer): GCNConv(\n",
      "          (model): GCNConv(300, 300)\n",
      "        )\n",
      "        (post_layer): Sequential(\n",
      "          (0): BatchNorm1d(300, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (1): ReLU()\n",
      "        )\n",
      "      )\n",
      "      (layer4): GeneralLayer(\n",
      "        (layer): GCNConv(\n",
      "          (model): GCNConv(300, 300)\n",
      "        )\n",
      "        (post_layer): Sequential(\n",
      "          (0): BatchNorm1d(300, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (1): ReLU()\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (post_mp): GNNGraphHead(\n",
      "      (layer_post_mp): MLP(\n",
      "        (model): Sequential(\n",
      "          (0): Linear(\n",
      "            (model): Linear(300, 10, bias=True)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "  )\n",
      ")\n",
      "accelerator: cuda\n",
      "benchmark: False\n",
      "bn:\n",
      "  eps: 1e-05\n",
      "  mom: 0.1\n",
      "cfg_dest: config.yaml\n",
      "custom_metrics: []\n",
      "dataset:\n",
      "  cache_load: False\n",
      "  cache_save: False\n",
      "  dir: ./datasets\n",
      "  edge_dim: 128\n",
      "  edge_encoder: False\n",
      "  edge_encoder_bn: True\n",
      "  edge_encoder_name: Bond\n",
      "  edge_encoder_num_types: 0\n",
      "  edge_message_ratio: 0.8\n",
      "  edge_negative_sampling_ratio: 1.0\n",
      "  edge_train_mode: all\n",
      "  encoder: True\n",
      "  encoder_bn: True\n",
      "  encoder_dim: 128\n",
      "  encoder_name: db\n",
      "  format: OGB\n",
      "  label_column: none\n",
      "  label_table: none\n",
      "  location: local\n",
      "  name: peptides-functional\n",
      "  node_encoder: True\n",
      "  node_encoder_bn: False\n",
      "  node_encoder_name: Atom\n",
      "  node_encoder_num_types: 0\n",
      "  remove_feature: False\n",
      "  resample_disjoint: False\n",
      "  resample_negative: False\n",
      "  shuffle_split: True\n",
      "  slic_compactness: 10\n",
      "  split: [0.8, 0.1, 0.1]\n",
      "  split_dir: ./splits\n",
      "  split_index: 0\n",
      "  split_mode: standard\n",
      "  task: graph\n",
      "  task_type: classification_multilabel\n",
      "  to_undirected: False\n",
      "  transductive: False\n",
      "  transform: none\n",
      "  tu_simple: True\n",
      "device: cuda\n",
      "devices: 1\n",
      "example_arg: example\n",
      "example_group:\n",
      "  example_arg: example\n",
      "gnn:\n",
      "  act: relu\n",
      "  agg: mean\n",
      "  att_final_linear: False\n",
      "  att_final_linear_bn: False\n",
      "  att_heads: 1\n",
      "  batchnorm: True\n",
      "  clear_feature: True\n",
      "  dim_inner: 300\n",
      "  dropout: 0.0\n",
      "  head: graph\n",
      "  keep_edge: 0.5\n",
      "  l2norm: True\n",
      "  layer_type: gcnconv\n",
      "  layers_mp: 5\n",
      "  layers_post_mp: 1\n",
      "  layers_pre_mp: 0\n",
      "  msg_direction: single\n",
      "  normalize_adj: False\n",
      "  residual: False\n",
      "  self_msg: concat\n",
      "  skip_every: 1\n",
      "  stage_type: stack\n",
      "gpu_mem: False\n",
      "gt:\n",
      "  attn_dropout: 0.0\n",
      "  batch_norm: True\n",
      "  bigbird:\n",
      "    add_cross_attention: False\n",
      "    attention_type: block_sparse\n",
      "    block_size: 3\n",
      "    chunk_size_feed_forward: 0\n",
      "    hidden_act: relu\n",
      "    is_decoder: False\n",
      "    layer_norm_eps: 1e-06\n",
      "    max_position_embeddings: 128\n",
      "    num_random_blocks: 3\n",
      "    use_bias: False\n",
      "  dim_hidden: 64\n",
      "  dropout: 0.0\n",
      "  full_graph: True\n",
      "  gamma: 1e-05\n",
      "  layer_norm: False\n",
      "  layer_type: SANLayer\n",
      "  layers: 3\n",
      "  n_heads: 8\n",
      "  pna_degrees: []\n",
      "  residual: True\n",
      "mem:\n",
      "  inplace: False\n",
      "metric_agg: argmax\n",
      "metric_best: ap\n",
      "model:\n",
      "  edge_decoding: dot\n",
      "  graph_pooling: mean\n",
      "  loss_fun: cross_entropy\n",
      "  match_upper: True\n",
      "  size_average: mean\n",
      "  thresh: 0.5\n",
      "  type: gnn\n",
      "name_tag: \n",
      "num_threads: 6\n",
      "num_workers: 0\n",
      "optim:\n",
      "  base_lr: 0.01\n",
      "  batch_accumulation: 1\n",
      "  clip_grad_norm: False\n",
      "  lr_decay: 0.1\n",
      "  max_epoch: 200\n",
      "  min_lr: 0.0\n",
      "  momentum: 0.9\n",
      "  num_warmup_epochs: 50\n",
      "  optimizer: adam\n",
      "  reduce_factor: 0.1\n",
      "  schedule_patience: 10\n",
      "  scheduler: cos\n",
      "  steps: [30, 60, 90]\n",
      "  weight_decay: 0.0005\n",
      "optimizer_config:\n",
      "  base_lr: 0.001\n",
      "  max_epoch: 500\n",
      "  min_lr: 1e-5\n",
      "  optimizer: adamW\n",
      "  reduce_factor: 0.5\n",
      "  schedule_patience: 20\n",
      "  scheduler: reduce_on_plateau\n",
      "  weight_decay: 0.0\n",
      "out_dir: results/peptides-func-GCN\n",
      "posenc_ElstaticSE:\n",
      "  dim_pe: 16\n",
      "  enable: False\n",
      "  kernel:\n",
      "    times: []\n",
      "    times_func: range(10)\n",
      "  layers: 3\n",
      "  model: none\n",
      "  n_heads: 4\n",
      "  pass_as_var: False\n",
      "  post_layers: 0\n",
      "  raw_norm_type: none\n",
      "posenc_EquivStableLapPE:\n",
      "  eigen:\n",
      "    eigvec_norm: L2\n",
      "    laplacian_norm: sym\n",
      "    max_freqs: 10\n",
      "  enable: False\n",
      "  raw_norm_type: none\n",
      "posenc_HKdiagSE:\n",
      "  dim_pe: 16\n",
      "  enable: False\n",
      "  kernel:\n",
      "    times: []\n",
      "    times_func: \n",
      "  layers: 3\n",
      "  model: none\n",
      "  n_heads: 4\n",
      "  pass_as_var: False\n",
      "  post_layers: 0\n",
      "  raw_norm_type: none\n",
      "posenc_LapPE:\n",
      "  dim_pe: 16\n",
      "  eigen:\n",
      "    eigvec_norm: L2\n",
      "    laplacian_norm: sym\n",
      "    max_freqs: 10\n",
      "  enable: False\n",
      "  layers: 3\n",
      "  model: none\n",
      "  n_heads: 4\n",
      "  pass_as_var: False\n",
      "  post_layers: 0\n",
      "  raw_norm_type: none\n",
      "posenc_LapPEVec:\n",
      "  dim_pe: 16\n",
      "  eigen:\n",
      "    eigvec_norm: L2\n",
      "    laplacian_norm: sym\n",
      "    max_freqs: 10\n",
      "  enable: False\n",
      "  layers: 3\n",
      "  model: none\n",
      "  n_heads: 4\n",
      "  pass_as_var: False\n",
      "  post_layers: 0\n",
      "  raw_norm_type: none\n",
      "posenc_RWSE:\n",
      "  dim_pe: 16\n",
      "  enable: False\n",
      "  kernel:\n",
      "    times: []\n",
      "    times_func: \n",
      "  layers: 3\n",
      "  model: none\n",
      "  n_heads: 4\n",
      "  pass_as_var: False\n",
      "  post_layers: 0\n",
      "  raw_norm_type: none\n",
      "posenc_SignNet:\n",
      "  dim_pe: 16\n",
      "  eigen:\n",
      "    eigvec_norm: L2\n",
      "    laplacian_norm: sym\n",
      "    max_freqs: 10\n",
      "  enable: False\n",
      "  layers: 3\n",
      "  model: none\n",
      "  n_heads: 4\n",
      "  pass_as_var: False\n",
      "  phi_hidden_dim: 64\n",
      "  phi_out_dim: 4\n",
      "  post_layers: 0\n",
      "  raw_norm_type: none\n",
      "print: both\n",
      "round: 5\n",
      "run_dir: results/peptides-func-GCN/0\n",
      "run_id: 0\n",
      "run_multiple_splits: []\n",
      "seed: 0\n",
      "share:\n",
      "  dim_in: 9\n",
      "  dim_out: 10\n",
      "  num_splits: 3\n",
      "tensorboard_agg: True\n",
      "tensorboard_each_run: False\n",
      "train:\n",
      "  auto_resume: False\n",
      "  batch_size: 128\n",
      "  ckpt_clean: True\n",
      "  ckpt_period: 100\n",
      "  enable_ckpt: True\n",
      "  epoch_resume: -1\n",
      "  eval_period: 1\n",
      "  finetune: \n",
      "  freeze_pretrained: False\n",
      "  iter_per_epoch: 32\n",
      "  mode: custom\n",
      "  neighbor_sizes: [20, 15, 10, 5]\n",
      "  node_per_graph: 32\n",
      "  radius: extend\n",
      "  sample_node: False\n",
      "  sampler: full_batch\n",
      "  skip_train_eval: False\n",
      "  walk_length: 4\n",
      "val:\n",
      "  node_per_graph: 32\n",
      "  radius: extend\n",
      "  sample_node: False\n",
      "  sampler: full_batch\n",
      "view_emb: False\n",
      "wandb:\n",
      "  entity: kludge\n",
      "  name: \n",
      "  project: peptides-func\n",
      "  use: False\n",
      "Num parameters: 508210\n",
      "Start from epoch 0\n",
      "train: 79it [00:17,  4.41it/s]^C\n",
      "train: 79it [00:18,  4.39it/s]\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/schwollie/Documents/Code/Uni/paper/experiment1/main.py\", line 176, in <module>\n",
      "    train_dict[cfg.train.mode](loggers, loaders, model, optimizer,\n",
      "  File \"/home/schwollie/Documents/Code/Uni/paper/experiment1/graphgps/train/custom_train.py\", line 126, in custom_train\n",
      "    train_epoch(loggers[0], loaders[0], model, optimizer, scheduler,\n",
      "  File \"/home/schwollie/Documents/Code/Uni/paper/experiment1/graphgps/train/custom_train.py\", line 47, in train_epoch\n",
      "    loss=loss.detach().cpu().item(),\n",
      "         ^^^^^^^^^^^^^^^^^^^\n",
      "KeyboardInterrupt\n"
     ]
    }
   ],
   "source": [
    "%cd experiment1\n",
    "!cat runAll.sh \n",
    "!chmod +x runAll.sh\n",
    "!bash -i ./runAll.sh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80251f20-4df1-4b88-bcbf-0f41f0efcc83",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "paper-kernel",
   "language": "python",
   "name": "paper-kernel"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
